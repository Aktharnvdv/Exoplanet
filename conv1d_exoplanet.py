# -*- coding: utf-8 -*-
"""conv1D_exoplanet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Q1oUyR4TjmjZ1mqhwAGR_VTuUwkhlj2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage.filters import uniform_filter1d, gaussian_filter
from sklearn.metrics import accuracy_score, precision_score, recall_score, \
                            confusion_matrix, fbeta_score, precision_recall_curve, \
                            average_precision_score, auc
from keras import backend as K
from keras.models import Sequential, Model
from keras.layers import Conv1D, MaxPool1D, Dense, Dropout, Flatten, \
BatchNormalization, Input, concatenate, Activation
from keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')
from inspect import signature
from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Commented out IPython magic to ensure Python compatibility.
class model_class:

  def __init__(self,link_for_trainset,link_for_testset):

    print("Loading datasets...")
    self.train = pd.read_csv(link_for_trainset, encoding= "ISO-8859-1")  
    self.test =pd.read_csv(link_for_testset, encoding= "ISO-8859-1") 
    self.x_train = self.train.drop('LABEL', axis=1)
    self.x_test = self.test.drop('LABEL', axis=1)
    self.y_train = self.train.LABEL
    self.y_test = self.test.LABEL
    self.x_train = np.array(self.x_train)
    self.y_train = np.array(self.y_train).reshape((-1,1))-1
    self.x_test = np.array(self.x_test)
    self.y_test = np.array(self.y_test).reshape((-1,1))-1 
    
    self.x_train = np.append(self.x_train, np.flip(self.x_train[0:37,:], axis=-1), axis=0)
    self.y_train = np.append(self.y_train, self.y_train[0:37]).reshape((-1,1))
    self.x_test = np.append(self.x_test, np.flip(self.x_test[0:5,:], axis=-1), axis=0)
    self.y_test = np.append(self.y_test, self.y_test[0:5]).reshape((-1,1))
    
    def detrender_normalizer(light_flux):
      flux1 = light_flux
      flux2 = gaussian_filter(flux1, sigma=10)
      flux3 = flux1 - flux2
      flux3normalized = (flux3-np.mean(flux3)) / (np.max(flux3)-np.min(flux3))
      return flux3normalized
    
    self.x_train_p = detrender_normalizer(self.x_train)
    self.x_test_p = detrender_normalizer(self.x_test)
    
    self.x_train = ((self.x_train - np.mean(self.x_train, axis=1).reshape(-1,1)) / np.std(self.x_train, axis=1).reshape(-1,1))
    self.x_test = ((self.x_test - np.mean(self.x_test, axis=1).reshape(-1,1)) / np.std(self.x_test, axis=1).reshape(-1,1))
  
    self.x_train = np.stack([self.x_train, self.x_train_p], axis=2)
    self.x_test = np.stack([self.x_test, self.x_test_p], axis=2)
    
    self.model = Sequential()
    self.model.add(Conv1D(filters=8, kernel_size=11, activation='linear', input_shape=self.x_train.shape[1:]))
    self.model.add(MaxPool1D(strides=4))
    self.model.add(BatchNormalization())
    self.model.add(Conv1D(filters=16, kernel_size=11, activation='relu'))
    self.model.add(MaxPool1D(strides=4))
    self.model.add(BatchNormalization())
    self.model.add(Conv1D(filters=32, kernel_size=11, activation='relu'))
    self.model.add(MaxPool1D(strides=4))
    self.model.add(BatchNormalization())
    self.model.add(Conv1D(filters=64, kernel_size=11, activation='relu'))
    self.model.add(MaxPool1D(strides=4))
    self.model.add(Flatten())
    self.model.add(Dropout(0.5)) 
    self.model.add(Dense(64, activation='relu'))
    self.model.add(Dropout(0.25)) 
    self.model.add(Dense(64, activation='relu'))
    self.model.add(Dense(1, activation='sigmoid'))

  def return_model(self): return self.model

  def return_data(self):

    data = {"x_train" : self.x_train , "x_test" : self.x_test , "y_train" : self.y_train , "y_test" : self.y_test}
    return data
    
    
  def shuffle_in_unison(self , a , b):
    rng_state = np.random.get_state()
    np.random.shuffle(a)
    np.random.set_state(rng_state)
    np.random.shuffle(b)

  def batch_generator(self , x_train , y_train , batch_size=32):

        half_batch = batch_size // 2
        x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32') 
        y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32') 

        while True:
            pos_idx = np.where(y_train[:,0] == 1)[0]
            neg_idx = np.where(y_train[:,0] == 0)[0]
            
            np.random.shuffle(pos_idx)
            np.random.shuffle(neg_idx)

            x_batch[:half_batch] = x_train[pos_idx[:half_batch]]
            x_batch[half_batch:] = x_train[neg_idx[half_batch:batch_size]] 
            y_batch[:half_batch] = y_train[pos_idx[:half_batch]]
            y_batch[half_batch:] = y_train[neg_idx[half_batch:batch_size]]
            
            self.shuffle_in_unison(x_batch,y_batch)

            for i in range(batch_size):
                sz = np.random.randint(x_batch.shape[1])
                x_batch[i] = np.roll(x_batch[i], sz, axis = 0)
            yield x_batch, y_batch

  def model_compile(self , model , x_train , y_train , x_test , y_test ):

    model.compile(optimizer=Adam(1e-5), loss = 'binary_crossentropy', metrics=['accuracy'])
    hist = model.fit_generator(self.batch_generator(x_train, y_train, 32),validation_data=(x_test, y_test), \
                                verbose=0, epochs=5,steps_per_epoch=x_train.shape[0]//32)

    model.compile(optimizer=Adam(4e-5), loss = 'binary_crossentropy', metrics=['accuracy'])
    hist = model.fit_generator(self.batch_generator(x_train, y_train, 32),validation_data=(x_test, y_test), 
                                verbose=2, epochs=50,steps_per_epoch=x_train.shape[0]//32)

    model_json = model.to_json()
    with open("/content/gdrive/My Drive/model.json", "w") as  json_file:
      json_file.write(model_json)
    model.save_weights("/content/gdrive/My Drive/model.h5")
    print("Saved model to disk")
    return hist ,  model

  def plot_validation(self , hist):

    plt.plot(hist.history['loss'], color='b',label='loss')
    plt.plot(hist.history['val_loss'], color='r',label='validation loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.legend(loc='upper right')
    images_dir = '/content/gdrive/My Drive'
    plt.savefig(f"{images_dir}/cnn_plot_0.png")
    plt.show()
    plt.plot(hist.history['accuracy'], color='b',label='accuracy')
    plt.plot(hist.history['val_accuracy'], color='r',label='validation accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.legend(loc='upper right')
    images_dir = '/content/gdrive/My Drive'
    plt.savefig(f"{images_dir}/cnn_plot_1.png")
    plt.show()
    
  def prediction_training_data(self , model , x_train , y_train):

    self.shuffle_in_unison(x_train,y_train)
    y_pred = model.predict(x_train)[:,0]
    pred = np.empty((1,len(y_pred)), dtype=object)
    pred = np.where(y_pred>=0.5, 1, 0)
    y_train = np.reshape(y_train,len(y_train))
    pred = np.reshape(pred,len(pred))
    
    print('Validation for training data:')
    conf_matrix = pd.crosstab(y_train, pred)
    print(conf_matrix)
    
    accuracy = accuracy_score(y_train, pred)
    precision = precision_score(y_train, pred)
    recall = recall_score(y_train, pred)
    fbeta = fbeta_score(y_train, pred, 1)
    print('Accuracy: %.3f Precision: %.3f Recall: %.3f F_beta: %.3f' \
#           % (accuracy, precision, recall, fbeta))
    
    precision, recall, thresholds = precision_recall_curve(y_train, y_pred, pos_label=1)
    auc_pr = auc(recall, precision)
    print('Area under precision-recall-curve: %.3f' % (auc_pr))
    step_kwargs = ({'step': 'post'}
                   if 'step' in signature(plt.fill_between).parameters
                   else {})
    plt.step(recall, precision, color='b', alpha=0.2,
             where='post')
    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title('Precision-Recall Curve')
    images_dir = '/content/gdrive/My Drive'
    plt.savefig(f"{images_dir}/cnn_plot_2.png")
    plt.show()

  def prediction_test_data(self , x_test , y_test , model):
    self.shuffle_in_unison(x_test,y_test)
    y_pred = model.predict(x_test)[:,0] 
    pred = np.empty((1,len(y_pred)), dtype=object)
    pred = np.where(y_pred>=0.5, 1, 0)
    y_test = np.reshape(y_test,len(y_test))
    pred = np.reshape(pred,len(pred))
    
    print('Validation for test data:')
    conf_matrix = pd.crosstab(y_test, pred)
    print(conf_matrix)
    
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    fbeta = fbeta_score(y_test, pred, 1)
    print('Accuracy: %.3f Precision: %.3f Recall: %.3f F_beta: %.3f' \
#           % (accuracy, precision, recall, fbeta))
    
    precision, recall, thresholds = precision_recall_curve(y_test, y_pred, pos_label=1)
    auc_pr = auc(recall, precision)
    print('Area under precision-recall-curve: %.3f' % (auc_pr))
    step_kwargs = ({'step': 'post'}
                   if 'step' in signature(plt.fill_between).parameters
                   else {})
    plt.step(recall, precision, color='b', alpha=0.2,
             where='post')
    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title('Precision-Recall Curve')
    images_dir = '/content/gdrive/My Drive'
    plt.savefig(f"{images_dir}/cnn_plot_3.png")
    plt.show()

if __name__ == '__main__':

    print("In main")

    M = model_class("/content/gdrive/My Drive/exoTrain.csv" , "/content/gdrive/My Drive/exoTest.csv")

    model = M.return_model()

    data = M.return_data()

    hist , model = M.model_compile(model , data["x_train"] , data["y_train"] , data["x_test"] , data["y_test"])

    M.plot_validation(hist)

    M.prediction_training_data(model , data["x_train"] ,data["y_train"] )

    M.prediction_test_data(data["x_test"] , data["y_test"] , model)

